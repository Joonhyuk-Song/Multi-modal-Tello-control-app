{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taHWSYUfLXxC"
   },
   "outputs": [],
   "source": [
    "!wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJd28iQlKiCE"
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1900,
     "status": "ok",
     "timestamp": 1739481342008,
     "user": {
      "displayName": "송준혁",
      "userId": "09689050530031006295"
     },
     "user_tz": 480
    },
    "id": "gQYpXwcMIjtF",
    "outputId": "52b18add-3c98-4b1d-f5a4-97b176b330fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"/content/drive/Shareddrives/Project_Engineering_Success/Project_Engineering_Success.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sI06FrH1LMk9"
   },
   "outputs": [],
   "source": [
    "#@markdown We implemented some functions to visualize the hand landmark detection results. <br/> Run the following cell to activate the functions.\n",
    "\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "\n",
    "MARGIN = 10  # pixels\n",
    "FONT_SIZE = 1\n",
    "FONT_THICKNESS = 1\n",
    "HANDEDNESS_TEXT_COLOR = (88, 205, 54) # vibrant green\n",
    "\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "  hand_landmarks_list = detection_result.hand_landmarks\n",
    "  handedness_list = detection_result.handedness\n",
    "  annotated_image = np.copy(rgb_image)\n",
    "\n",
    "  # Loop through the detected hands to visualize.\n",
    "  for idx in range(len(hand_landmarks_list)):\n",
    "    hand_landmarks = hand_landmarks_list[idx]\n",
    "    handedness = handedness_list[idx]\n",
    "\n",
    "    # Draw the hand landmarks.\n",
    "    hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "    hand_landmarks_proto.landmark.extend([\n",
    "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks\n",
    "    ])\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "      annotated_image,\n",
    "      hand_landmarks_proto,\n",
    "      solutions.hands.HAND_CONNECTIONS,\n",
    "      solutions.drawing_styles.get_default_hand_landmarks_style(),\n",
    "      solutions.drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "    # Get the top left corner of the detected hand's bounding box.\n",
    "    height, width, _ = annotated_image.shape\n",
    "    x_coordinates = [landmark.x for landmark in hand_landmarks]\n",
    "    y_coordinates = [landmark.y for landmark in hand_landmarks]\n",
    "    text_x = int(min(x_coordinates) * width)\n",
    "    text_y = int(min(y_coordinates) * height) - MARGIN\n",
    "\n",
    "    # Draw handedness (left or right hand) on the image.\n",
    "    cv2.putText(annotated_image, f\"{handedness[0].category_name}\",\n",
    "                (text_x, text_y), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                FONT_SIZE, HANDEDNESS_TEXT_COLOR, FONT_THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "  return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXOjRPbaKs8_"
   },
   "outputs": [],
   "source": [
    "# STEP 1: Import the necessary modules.\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "\n",
    "# STEP 2: Create an HandLandmarker object.\n",
    "base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
    "options = vision.HandLandmarkerOptions(base_options=base_options,\n",
    "                                       num_hands=2)\n",
    "detector = vision.HandLandmarker.create_from_options(options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lrdsodT7K8mP"
   },
   "outputs": [],
   "source": [
    "\n",
    "def convert2numpy(detection_result):\n",
    "    hand_landmarks_list = detection_result.hand_landmarks\n",
    "    # Check if the list is not empty\n",
    "    if not hand_landmarks_list:\n",
    "        print(\"No landmarks detected!\")\n",
    "        # Return a padded array of zeros (21 landmarks x 3 coordinates)\n",
    "        return np.zeros((21, 3), dtype=np.float32)\n",
    "\n",
    "    # Assuming at least one hand is detected, we extract the first hand's landmarks\n",
    "    landmark_list = [\n",
    "        (landmark.x, landmark.y, landmark.z)\n",
    "        for landmark in hand_landmarks_list[0]  # Iterate through the first hand's landmarks\n",
    "    ]\n",
    "    # Convert to NumPy array\n",
    "    landmark_array = np.array(landmark_list, dtype=np.float32)\n",
    "    return landmark_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1739481576810,
     "user": {
      "displayName": "송준혁",
      "userId": "09689050530031006295"
     },
     "user_tz": 480
    },
    "id": "istVP5FELUjW",
    "outputId": "fa858b6e-c784-4bd2-9f8f-9ce23cfb9a44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n",
      "Predicted Gesture: Back\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the label map (reverse mapping)\n",
    "label_map = {0: 'Right', 1: 'Down', 2: 'Fist', 3: 'Front',\n",
    "             4: 'Left', 5: 'None', 6: 'Up', 7: 'Back'}\n",
    "\n",
    "# Function to decode one-hot encoded labels\n",
    "def decode_label(one_hot_vector):\n",
    "    return label_map[np.argmax(one_hot_vector)]  # Get the class index and map it\n",
    "\n",
    "# Perform inference on an image\n",
    "def predict_image(image_path):\n",
    "    image = mp.Image.create_from_file(image_path)\n",
    "    detection_result = detector.detect(image)\n",
    "    data=convert2numpy(detection_result)\n",
    "    batched_data = np.expand_dims(data, axis=0)\n",
    "\n",
    "    # Get prediction\n",
    "    prediction = model.predict(batched_data)\n",
    "    predicted_label = decode_label(prediction[0])  # Decode prediction\n",
    "\n",
    "    return predicted_label\n",
    "\n",
    "# Test the function\n",
    "image_path = \"/content/drive/Shareddrives/Project_Engineering_Success/rename_resizedataset3/Back/image_0002.jpg\"\n",
    "predicted_gesture = predict_image(image_path)\n",
    "\n",
    "print(f\"Predicted Gesture: {predicted_gesture}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lj6ESnfALoTt"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "import time\n",
    "\n",
    "def take_photo_at_fps(filename='photo.jpg', fps=10, quality=0.8):\n",
    "    js = Javascript('''\n",
    "    async function takePhoto(quality, fps) {\n",
    "        const div = document.createElement('div');\n",
    "        const capture = document.createElement('button');\n",
    "        capture.textContent = 'Capture';\n",
    "        div.appendChild(capture);\n",
    "\n",
    "        const video = document.createElement('video');\n",
    "        video.style.display = 'block';\n",
    "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "        document.body.appendChild(div);\n",
    "        div.appendChild(video);\n",
    "        video.srcObject = stream;\n",
    "        await video.play();\n",
    "\n",
    "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "        let captureInterval = setInterval(async function() {\n",
    "            // Capture a frame every fps seconds\n",
    "            capture.click();\n",
    "        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n",
    "\n",
    "        // Wait for Capture to be clicked\n",
    "        await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "        clearInterval(captureInterval);  // Stop the interval after capturing\n",
    "\n",
    "        const canvas = document.createElement('canvas');\n",
    "        canvas.width = video.videoWidth;\n",
    "        canvas.height = video.videoHeight;\n",
    "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "        stream.getVideoTracks()[0].stop();\n",
    "        div.remove();\n",
    "        return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "\n",
    "    display(js)\n",
    "    # Capture the photo after a specified time interval (fps)\n",
    "    data = eval_js(f'takePhoto({quality}, {fps})')\n",
    "    binary = b64decode(data.split(',')[1])\n",
    "\n",
    "    # Save the captured image to the specified file\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(binary)\n",
    "\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 65978,
     "status": "error",
     "timestamp": 1739483526765,
     "user": {
      "displayName": "송준혁",
      "userId": "09689050530031006295"
     },
     "user_tz": 480
    },
    "id": "FswAz356LupN",
    "outputId": "46c65023-fba4-4ae8-a239-6c9b49bbbd32"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Predicted Gesture: Down\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Predicted Gesture: Front\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Predicted Gesture: Front\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Predicted Gesture: Front\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Predicted Gesture: Front\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Predicted Gesture: Front\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Predicted Gesture: Right\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Predicted Gesture: Right\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Predicted Gesture: Left\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Predicted Gesture: Left\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Predicted Gesture: Left\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Predicted Gesture: Up\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Predicted Gesture: Down\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Predicted Gesture: Up\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Predicted Gesture: Down\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Predicted Gesture: Down\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Predicted Gesture: Up\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Predicted Gesture: Down\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Predicted Gesture: Down\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Predicted Gesture: Down\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Predicted Gesture: Down\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Predicted Gesture: Right\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Predicted Gesture: Down\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Predicted Gesture: Down\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Predicted Gesture: Up\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No landmarks detected!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Predicted Gesture: Fist\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function takePhoto(quality, fps) {\n        const div = document.createElement('div');\n        const capture = document.createElement('button');\n        capture.textContent = 'Capture';\n        div.appendChild(capture);\n\n        const video = document.createElement('video');\n        video.style.display = 'block';\n        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n        document.body.appendChild(div);\n        div.appendChild(video);\n        video.srcObject = stream;\n        await video.play();\n\n        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n        let captureInterval = setInterval(async function() {\n            // Capture a frame every fps seconds\n            capture.click();\n        }, 1000 / fps);  // Interval in milliseconds (1 / fps)\n\n        // Wait for Capture to be clicked\n        await new Promise((resolve) => capture.onclick = resolve);\n\n        clearInterval(captureInterval);  // Stop the interval after capturing\n\n        const canvas = document.createElement('canvas');\n        canvas.width = video.videoWidth;\n        canvas.height = video.videoHeight;\n        canvas.getContext('2d').drawImage(video, 0, 0);\n        stream.getVideoTracks()[0].stop();\n        div.remove();\n        return canvas.toDataURL('image/jpeg', quality);\n    }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-fc021964abd5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtake_photo_at_fps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mpredicted_gesture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-e39c60d633e7>\u001b[0m in \u001b[0;36mtake_photo_at_fps\u001b[0;34m(filename, fps, quality)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Capture the photo after a specified time interval (fps)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'takePhoto({quality}, {fps})'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb64decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def detector():\n",
    "  filename = take_photo_at_fps()\n",
    "  image = Image.open(filename)\n",
    "  predicted_gesture = predict_image(filename)\n",
    "  return predicted_gesture\n",
    "\n",
    "def \n",
    "\n",
    "while True:\n",
    "  detector()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
